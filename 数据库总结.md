#  MySQL常见面试题

##  事务四大特性

- 原子性：事务要么全部执行，要么全部不执行，是不可分割的工作单位。
- 一致性：指事务开始之前和结束以后，完整性约束没有被破坏。
- 隔离性：多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果。
- 持久性：意味着事务在完成之后，该事务对数据库所作的更改便持久的保存在数据库中，并不会被回滚。

##  事务的并发、隔离级别

###  并发

理论上来说，事务应该彼此完全隔离，以避免并发事务所导致的问题，然而会对性能产生极大的影响，因为事务必须按顺序运行，**在实际开发中，为了提升性能，事务会以较低的隔离级别运行，事务的隔离级别可以通过隔离事务属性指定。**

###  事务的并发问题

1. 脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据。
2. 丢失修改：指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务修改的结果就会丢失，因此称为丢失修改。
3. 不可重复读：事务A多次读取同一数据，事务B在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，出现的结果不一致。
4. 幻读：解决了不重复读，保证了同一个事务里，查询的结果都是事务开始时的状态。比如说，当A事务将表中c字段的值都改为3，而B事务新增一条数据，c字段为2，那么此时再查看数据会发现有一条并没有修改，这就是幻读。

### 事务隔离级别

1. 读未提交：即能够读取到没有被提交的数据。

2. 读已提交：能够读到已提交的数据。

3. 重复读取：即在数据读出来之后加锁，防止别人修改。MySQL默认隔离级别。

4. 串行化：最高的事务隔离级别，不管多少事务，挨个运行完一个事务的所有子事务之后才可以执行另外一个事务里面的所有子事务。

5. | 事务隔离级别 | 脏读 | 不可重复读 | 幻读 |
   | :----------: | :--: | :--------: | :--: |
   |   读未提交   |  Y   |     Y      |  Y   |
   |   读已提交   |  N   |     Y      |  Y   |
   |   可重复读   |  N   |     N      |  Y   |
   |    串行化    |  N   |     N      |  N   |

##  MySQL常见的存储引擎及应用场景

###  存储引擎

MySQL中的数据用各种不同的技术存储在文件（内存）中。

###  MyISAM和InnoDB的区别

- InnoDb支持事务，对于InnoDB来说每一条SQL语句都默认封装为事务，自动提交，这样会影响效率，最好把多条SQL语句放在begin和commit之间，组成一个事务。

  ```sql
  set autocommit = 0;
  ```

- InnoDB支持外键，MyISAM不支持，对一个包含外键的InnoDB表转为MyISAM会失败。

- InnoDB和MyISAM都是采用B+树作为索引结构，但InnoDB数据文件和索引是在一起的，而MyISAM则是分开存储的，查询的时候还需要通过地址再查询一次。（InnoDB是聚集索引，MyISAM是非聚集索引）

- InnoDB支持表、行级锁，而MyISAM支持表级锁，锁的粒度不一样。

- InnoDB必须有主键，用户如果没有指定则会自己找或生产一个主键，而MyISAM可以没有。

- InnoDB存储文件有表定义，数据和索引两个文件，而MyISAM是表定义、数据文件和索引文件。

####  如何选择

- 如果要支持事务，请选择InnoDB
- 如果大多只是读查询，选择MyISAM
- 系统崩溃后，MyISAM恢复起来更困难
- 如果不知道用什么，请用InnoDB，它是5.5之后的默认引擎

###  MEMORY

- 使用存在于内存中的内容来创建表，访问速度快，默认使用HASH索引，服务关闭数据会丢失
- 用于内容变化不频繁的代码表，或者作为统计操作的中间结果表

##  查询语句不同元素执行先后顺序

- from：从后往前、从右到左，数据量较少的表尽量放在后面
- where：从下往上、从右到左，将能过滤掉最大数量记录的条件写在where子句的最右
- group by：从左往右分组，最好在group by前使用where，将不需要的记录在group by之前过滤掉
- having：消耗资源，避免使用，having会在检索出所有记录之后才对结果集进行过滤，需要排序等操作
- select：少用*，尽量取字段名称
- order by：从左到右排序，消耗资源

##  什么是临时表？什么时候删除？

###  临时表

用于存储一些中间结果集的表，临时表只在当前连接可见，当关系连接时，MySQL会自动删除表并释放所有空间。

###  分类

- 内存临时表
  采用memory存储引擎
- 磁盘临时表
  采用myisam引擎

###  下列操作会使用到临时表

- union查询
- 对于视图的操作
- 子查询
- join，包括not in、exist
- 复杂的group by、order by

##  索引的优缺点

###  优点

- 加快数据的检索速度，最主要原因
- 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间
- 通过使用索引，可以在查询中使用优化隐藏器，提高系统的性能

###  缺点

- 创建索引和维护索引要耗费时间，随着数据量的增加而增加
- 会占用物理空间，除了数据表占用数据空间之外，每个索引还要占一定的物理空间
- 数据的增、删、改会慢，需要维护索引

##  索引建立的过程

Innodb中存储空间管理的最小单位是页，页的默认是16KB，每个页中存放了数据。页与页之间是通过双向链表来建立的，索引中的数据都会按照主键的值从小到大排列并用单向链表链接起来。在建立目录的过程中规定了下一个数据页的主键值必须大于上一个数据页的主键值。当一个页中的数据超出了范围就产生一个新的页存放，这个过程会产生页分裂，数据的移动，比如主键值小的会跑去上一个页，主键值大的往后一个页移动。

存在的问题是页与页之间不是相邻的，假如上一个页的页号为10，下一个为20，但是页之间是通过双向链表进行连接，为了快速的访问到特定的页号就需要再为每个目录页建立一个目录项。每一个目录项中包括了两个内容，一个是目录项中的最小主键值，另一个是页目录号（页号），这样就可以快速的根据主键值定位到一条记录，这种目录项就叫做索引。

##  B-Tree索引、B+Tree索引、Hash索引的区别

###  B-Tree

- 叶子节点具有相同的深度，叶子节点的指针为空
- 所有索引元素不重复，每个节点最多含有m个孩子（m>=2)
- 所有键值分布在整个树中
- 节点总的数据索引从左到右递增排列

###  B+Tree

- 非叶子节点不存储data（Innodb中存储空间管理的最小单位是页，页的默认是16KB），只存储索引（冗余），可以放更多的索引，一旦放数据，那么树就会增高，IO次数就越多（我们在设计索引的时候要求索引尽可能占空间小，那么就会放更多索引，树的高低就更低。）
- 叶子节点包含所有索引字段
- 叶子节点用指针连接，提高区间访问的性能

####  查找过程

假设要查找数据项29，那么首先会把磁盘块1由磁盘加载到内存，在内存中用二分查找确定29在17～35之间，然后再把磁盘2加载到内存，依次加载磁盘3使用二分查找找到29，结束查询，总计3次IO。真实的情况是，3层的B+树可以表示上百万的数据。

###  Hash索引

优点：索引自身只需存储对应的哈希值，所以索引的结构非常紧凑。

缺点：

- **不能避免读取行**：哈希索引只包含哈希值和行指针，而不存储字段值，所以不能使用索引中的值来避免读取行
- **无法用于排序**：哈希索引数据并不是按照索引值顺序存储的，所以也就无法用于排序
- **无法使用部分索引列匹配查找**：哈希索引是使用索引列的全部内容来计算哈希值的
- **只支持等值查找**：哈希索引只支持等值比较查询，不支持任何范围查询
- **存在hash冲突**：当出现哈希冲突的时候，存储引擎必须遍历链表中所有的行指针，逐行进行比较，直到找到所有符合条件的行

###  为什么选用B+Tree

- B+Tree是B-Tree的升级版，多路绝对平衡查找树，拥有B-Tree的优势
- B+Tree扫库、扫表能力更强
- 磁盘读写能力更强
- 排序能力更强
- 查询效率更加稳定

##  SQL查询语句如何确定创建哪种类型的索引？如何优化查询？

###  普通索引

####  创建方式

- create index  [indexname] on table(字段)
- alter table add index [indexname] on (字段)

###  唯一索引

索引列的值必须唯一，但允许有控制；如果是组合索引，那么组合必须唯一

####  创建方式

- create unique index [indexname] on table(字段)
- alter table add unique [indexname] on (字段)
- create table mytable(id int not null,unique[indexname] (id))

###  主键索引

是一种特殊的唯一索引，不允许有空值，在建表的时候同时创建主键索引，一个表只能有一个主键。

###  组合索引

alter table mytable add index [indexname] (字段1、字段2、字段3);

B+树是按照从左到右的顺序来建立搜索树的，假设有(name, age, sex)索引，当(张三, 20, F)这样的数据来检索的时候，就会优先比较name来确定下一步的搜索方向，如果name相同再依次比较age和sex，最后得到检索的数据；但当(20, F)这样的没有name的数据来的时候，B+树就不知道下一步该查那个节点，导致索引失效。



组合索引满足最左前缀法则，只能从左开始匹配，从中间开始或者中间断开，索引就会失效。

- 不在索引列上做任何操作（计算、函数、（自动or手动）类型转换，会导致索引失效转向全表扫描）
- 存储引擎不能使用索引中范围条件右边的列

> where a = 3 and b > 4 and c = 5;    //用到a、b索引
>
> where a = 3 and c = 5;   //用到a索引
>
> where a = 3 and b like '5%' and c = 5;  //a、b可以，c失效

- 尽量使用覆盖索引（只访问索引的查询（索引列和查询列一致）)，减少select *
- 避免使用不等于(!= 或者<>) ，is null、is not null，少用or

##  MySQL有哪些锁？

1. 粒度

   - 表锁（偏读）：偏向MyISAM存储引擎，开销小，加锁快；无死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。读锁会阻塞写不会阻塞读，写锁则会把读和写都阻塞。

   >lock table 表名 read(write) ;
   >
   >show open tables;     //查看表上过的锁
   >
   >unlock tables；

   - 行锁（偏写）：偏向InnoDB存储引擎，开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的概率最低，并发度最高。InnoDB的行锁并不是绝对的，例如在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB同样会锁全表，例如update table set num=1 where name like "%aa%"; 在where条件没有主键时，同样会锁全表。
   - 间隙锁：当我们用范围条件而不是相等条件检索数据，并请求共享锁或排它锁时，InnoDB会给符合条件的已有数记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做间隙，InnoDB也会对这个间隙加锁，这就是间隙锁。

2. 乐观锁：不是系统自带的，需要我们自己去实现，在表中的数据进行操作时，先给数据表加一个版本(version)字段，每操作一次，将那条记录的版本号加1，也就是先查询出那条记录，获取出version字段，如果要对那条记录进行操作，则先判断此刻 version的值是否与刚刚查询出来时的version的值相等。如果相等，则这段时间没有其他程序对其进行操作，可以执行更新，并且将version字段加1，如果不相等，则不进行更新操作。  避免了长事务中的数据库加锁解锁开销，适用于读多写少并发量高的情况下，如果并发量不大，也可以采用悲观锁的方法。
  

   悲观锁：是由系统自带的，在操作数据时，认为此操作会出现数据冲突，所以在进行每次操作时都要通过获取锁才能进行对相同数据的操作，所以悲观锁需要耗费较多的时间。共享锁和排他锁都是悲观锁的不同的实现。

3. 对数据操作

   - 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行而不会互相影响，通过在执行语句后加上lock in share mode
   - 写锁（排它锁）：当前写操作没有完成前，它会阻断其它写锁和读锁，在执行语句后加上for update

##  主从复制过程

1. master将改变记录写到二进制日志（binary log)，这些记录过程叫做二进制日志事件，binary log events
2. slave 将master的binary log events 拷贝到它的中继日志relay log
3. slave 重做中继日志中的事件，将改变应用到自己的数据库中，mysql复制是异步的且串行化的

###  主库宕机解决方案

1. 确保所有的relay log(从机会把binlog拷贝到本地的relaylog）全部更新完毕，在从库上执行stop slave io_thread直到查看has read all relay log，则更新完毕
2. 登陆所有从库，查看master.info文件，对比选择pos最大的作为新的主库
3. 登陆新的主库，执行stop slalve，进入数据库目录，删除master.info和relay-log.info，配置my.ini文件，开启log-bin
4. 创建用于同步的用户并授权slave
5. 将从库连到新的主库上，更新主库数据，查看是否同步更新

##  非关系型数据库和关系型数据库的区别

###  关系型数据库

采用了关系模型来组织数据的数据库，最大特点就是事务的一致性；简单来说，关系模型指的就是二维表格模型。

####  优点

1. 易于维护：都是使用表结构，格式一致
2. 使用方便：SQL语言通用，可用于复杂查询
3. 复杂操作：支持SQL，可用于一个表以及多个表之间非常复杂的查询

####  缺点

1. 读写性能比较差，尤其是海量数据的高效率读写
2. 固定的表结构，灵活度稍欠
3. 高并发读写需求，对于传统的关系型数据库来说，硬盘I/O是一个很大的瓶颈

####  应用场景

- 需要做复杂处理的数据
- 数据量不是特别大的数据
- 对安全性要求高的数据
- 数据格式单一的数据

###  非关系型数据库

使用键值对存储数据，是一种数据结构化存储方法的集合。

####  优点

1. 格式灵活：存储数据的格式可以是key-value形式、文档形式、图片形式等等，而关系型数据库则只支持基础类型
2. 速度快：NoSQL可以使用硬盘或者随机存储器作为载体，而关系型数据库只能使用硬盘
3. 高扩展性
4. 成本低：NoSQL数据库部署简单

#### 缺点

1. 不提供sql支持，学习和使用成本较高
2. 无事务处理
3. 数据结构相对复杂，复杂查询方面稍欠

####  应用场景

- 缓存（数据查询、短连接、新闻内容、商品内容等等）
- 聊天室的在线好友列表
- 任务队列（秒杀、抢购、12306）
- 应用排行榜
- 网站访问统计
- 分布式集群架构中的session分离

##  数据库三范式

为了建立冗余较小、结构合理的数据库，设计数据库时必须遵循一定的规则。在关系型数据库中这些规则就称为范式。

###  第一范式（确保每列保持原子性）

数据库表里面的字段都是不可再分的。如一般需求：地址字段需要分为省-->市-->县，因此设计成一个字段就不合适，需要设计三个及以上字段。

###  第二范式（确保表中的每列都和主键相关，消除部分依赖）

- 首先要满足第一范式
- 确保数据库表中的每一列都和主键相关，而不能与主键的某一部分有关。

###  第三范式（确保每列都和主键列直接相关，而不是间接相关，消除传递依赖，非主属性的依赖）

- 满足第二范式
- 确保直接相关，不能间接相关。

##  MySQL慢查询怎么解决

1. 通过explain优化SQL，查看该SQL有没有用上索引
   - 通过查看type来看对表的访问方式，all、index、range、ref等等（性能从差到好）
   - 通过查看possible_keys来查看哪个索引用到，哪个索引失效
   - 通过查看key来显示实际决定使用的索引，必然包含在possible_key中
   - 通过查看key_len来表示索引中使用的字节数即索引的最大可能长度
2. 优化分析
   - 观察，至少跑一天，查看慢SQL情况
   - 开启慢查询日志（set global slow_query_log = 1,在my.ini里配置日志路径），设置阈值，比如超过5s的就是慢SQL，并将它抓取出来（select sleep(5)）
   - show profile 查询sql在mysql服务器里面的执行细节和生命周期情况

##  varchar和char的使用场景

###  VARCHAR

存储可变长字符串，比定长类型更节省时间，但是需要1或2个额外字节记录字符串的长度。

####  使用场景

字符串列的最大长度比平均长度大很多；列的更新很少，碎片问题不大

###  CHAR

定长，根据需要采用空格进行填充，方便比较

####  使用场景

适合存储很短的字符串或长度都接近同一个长度，比如MD5值

###  区别

- 对于经常变更的数据，CHAR比VARCHAR好，因为定长的CHAR类型不容易产生碎片
- 对于非常短的列CHAR比VARCHAR效率更高，因为VARCHAR需要额外字节记录长度

##  MySQL高并发环境的解决方案

MySQL高并发环境解决方案：分库、分表、分布式、增加二级缓存

现有解决方式：水平分库分表，由单点分布到多点数据库中，从而降低单点数据库压力，引入负载均衡策略，读写分离策略。

###  分表时id的唯一性和递增

使用snowflake算法：核心思想是一个64位long型ID，使用41bit作为毫秒数，10bit作为机器的ID（5bit是数据中心，5bit是机器ID），12bit作为毫秒内的流水号（避免一毫秒插入多条数据）。

```java
/*
0-00000000 00000000 00000000 00000000 0 - 00000 - 00000 - 00000000 0000
由于long是带符号的，最高位是符号位，所以最高位固定为0
41位时间戳（毫秒级），41位时间戳不是存储当前时间的时间戳，而是存储时间戳的差值（当前-开始）
10位的数据机器位，可以部署1024个节点，包括五位datacenterId和五位workerId
12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒（同一机器、同一时间戳）产生4096个ID序号
SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞（由数据中心ID和机器ID作区分），并且效率极高，经测试，SnowFlake每秒能产生26万ID左
*/
package snowflake;

/**
 * @description
 * @author: Victor
 * @create: 2020-03-10 14:27
 **/
public class IdWorker {
    private static long workId;         //工作id
    private static long datacenterId;   //数据id
    private static long sequence;       //序列号

    private static long twepoch = 1288834974657L;
    private static long workIdBits = 5L;
    private static long datacenterIdBits = 5l;

    private long maxWorkId = -1L ^ (-1L << workIdBits);
    private long maxDatacenterId = -1L ^ (-1L << datacenterIdBits);

    private static long sequenceBits = 12L;
    private static long sequenceMask = -1L ^ (-1L << sequenceBits);
    private static long workerIdShift = sequenceBits;
    private static long datacenterIdShift = sequenceBits + workIdBits;
    private static long timestampLeftShift = sequenceBits + workIdBits + datacenterIdBits;
    private static long lastTimestamp = -1L;

    public IdWorker(long workId, long datacenterId, long sequence) {
        if (workId > maxWorkId || workId < 0) {
            throw new IllegalArgumentException();
        }
        if (datacenterId > maxDatacenterId || maxDatacenterId < 0) {
            throw new IllegalArgumentException();
        }
        this.workId = workId;
        this.datacenterId = datacenterId;
        this.sequence = sequence;
    }


    public long getWorkId() {
        return workId;
    }

    public static long getDatacenterId() {
        return datacenterId;
    }

    public static long getTimestamp() {
        return System.currentTimeMillis();
    }

    public static synchronized long nextId() {
        long timestamp = timeGen();
        if (timestamp < lastTimestamp) {
            lastTimestamp = timestamp;
        }
        if (lastTimestamp == timestamp) {
            sequence = (sequence+1) & sequenceMask;
            if (sequence == 0) {
                timestamp = tilNextMillis(lastTimestamp);
            }
        }else {
            sequence = 0;
        }
        lastTimestamp = timestamp;

        return ((timestamp - twepoch) << timestampLeftShift) | (datacenterId << datacenterIdShift)
                | (workId << workerIdShift) | sequence;
    }

    //获取系统时间戳，并与上次时间戳比较
    private static long tilNextMillis(long lastTimestamp) {
        long timestamp = timeGen();
        while (timestamp <= lastTimestamp) {
            timestamp = timeGen();
        }
        return timeGen();
    }

    //获取系统时间戳
    private static long timeGen() {
        return System.currentTimeMillis();
    }


    public static void main(String[] args) {
        IdWorker worker = new IdWorker(1, 1, 1);
        for (int i = 0; i < 30; i++) {
            System.out.println(worker.nextId());
        }
    }
}
```



##  MVCC

###  定义

MVCC是一种多版本并发控制协议，多版本的并发控制相当于传统的基于锁的并发控制主要特点是读不上锁，这种特性对于读多写少的场景，大大提高了系统的并发度，因此大部分关系型数据库都实现了MVCC。通过MVCC很好的实现了事务的隔离性，可以达到repeated read级别，要实现serializable还必须加锁。

###  解决什么问题

MVCC可以在大多数情况下代替行级锁，使用MVCC，能降低系统开销。MVCC是通过保存数据在某个时间点的快照来实现的。不同存储引擎的MVCC实现是不同的，典型的有乐观并发控制和悲观并发控制。

###  具体实现分析

InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列来实现的，这两个列，分别保存了这个行的创建版本号，一个保存的是行的删除版本号（系统版本号，可以理解为事务的ID）。每开始一个新的事务，系统版本号就会自动递增，事务开始时的版本号为事务的ID。

- select：满足以下两个条件InnoDB会返回该行数据
  1. 该行的创建版本号小于等于当前版本号，用于保证在select操作之前所有的操作已经执行落地
  2. 该行的删除版本号大于当前版本号或者为空，删除版本号大于当前版本意味着有一个并发事务将该行删除
- insert：将新插入的行的创建版本号设置为当前系统的版本号
- delete：将要插入的行的删除版本号设置为当前系统的版本号
- update；不执行原地update，而是转换成insert+delete。将旧行的删除版本号设置为当前版本号，并将新行insert同时设置创建版本号为当前版本号

##  数据库崩溃时事务的恢复机制（Redo日志和Undo日志）

###  Undo Log

UndoLog是为了实现事务的原子性，在MySQL数据库InnoDb存储引擎中，还用Undo Log来实现多版本并发控制。

####  原理

为了满足事务的原子性，在操作任何数据之前，首先将数据备份到一个地方（Undo Log）。然后进行数据的修改。如果出现了错误或者用户执行了rollback语句，系统就可以利用Undo Log中的备份将数据恢复到事务开始之前的状态。

#### 如何保证原子性和持久性

- 更新数据前记录Undo Log
- 为了保证持久性，必须将数据在事务提交前写到磁盘，只要事务成功提交，数据必然已经持久化
- Undo Log必须先于数据持久化到磁盘

####  缺陷

每个事务提交前将数据和Undo Log写入磁盘，这样会导致大量的磁盘IO，因此性能降低。如果能够将数据缓存一段时间，就能减少IO提高性能。但是这样会丧失事务的持久性。

###  Redo Log

原理和Undo Log相反，Redo Log记录的是新数据的备份。在事务提交前，只要将Redo Log持久化即可，不需要将数据持久化。当系统崩溃时，虽然数据没有持久化，但是Redo Log已经持久化。系统可以根据Redo Log的内容，将所有数据恢复到最新的状态。

##  如果数据库日志满了，会出现什么情况

日志文件（Log File）记录所有对数据库数据的修改，主要是保护数据库以防故障发生，以及恢复数据时使用，其特点如下：

- 每一个数据库至少包含两个日志文件组，每个日志文件组至少包括两个日志文件成员。
- 日志文件组以循环方式进行写操作。
- 每一个日志文件成员对应一个物理文件。

通过日志文件来记录数据库事务可以最大限度地保证数据的一致性与安全性，但一旦日志满了，就只能执行查询等读操作，不能执行更改、备份等操作，原因是任何写操作都要记录日志。

